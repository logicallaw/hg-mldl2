{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07-2 심층 신경망 (파이토치)",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9a9yphOyBOS8cE2VPWSgg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 심층 신경망 (파이토치)"
      ],
      "metadata": {
        "id": "fvpweBdmFXqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\"><tr><td>\n",
        "<a href=\"https://colab.research.google.com/github/rickiepark/hg-mldl2/blob/main/07-2.pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
        "</td></tr></table>"
      ],
      "metadata": {
        "id": "0E7dkJR8FXi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행마다 동일한 결과를 얻기 위해 파이토치에 랜덤 시드를 지정하고 GPU 연산을 결정적으로 만듭니다.\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "KIajgl2aEAzX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "fm_train = FashionMNIST(root='.', train=True, download=True)\n",
        "fm_test = FashionMNIST(root='.', train=False, download=True)"
      ],
      "metadata": {
        "id": "240rE4p-Hih8",
        "outputId": "3cb81f4c-3417-4ea3-a945-5ff41c490ae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.0MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 202kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.78MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(fm_train.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91hTn5Gp1StX",
        "outputId": "e9adb93f-9602-4a78-e81e-69ae0bf887d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fm_train.data.shape, fm_test.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wic0FYPY0e2D",
        "outputId": "1906a890-0397-4f22-dceb-e47ca4969dc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fm_train.targets.shape, fm_test.targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqOKT1Ry154_",
        "outputId": "cc054d62-fb00-498d-fd33-8e038ed09078"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000]) torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = fm_train.data\n",
        "train_target = fm_train.targets"
      ],
      "metadata": {
        "id": "Ep2HHMl92Ced"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_scaled = train_input / 255.0"
      ],
      "metadata": {
        "id": "oldlijP41Vb-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Fb6FsF1H1LQ9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_scaled.shape, val_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZvX0OeSAg0N",
        "outputId": "24e79c2d-ee81-485b-bd28-4801b76da169"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([48000, 28, 28]) torch.Size([12000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hiZNXVSWHOZe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90PBcqbHH_ym",
        "outputId": "ecc36ef5-4bc7-4a15-dbb3-8498c73d550b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size=(32, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcoB-NNoH7P7",
        "outputId": "f3301588-0cfd-4565-93d8-617b71d7f2d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Sequential                               [32, 10]                  --\n",
              "├─Flatten: 1-1                           [32, 784]                 --\n",
              "├─Linear: 1-2                            [32, 100]                 78,500\n",
              "├─ReLU: 1-3                              [32, 100]                 --\n",
              "├─Linear: 1-4                            [32, 10]                  1,010\n",
              "==========================================================================================\n",
              "Total params: 79,510\n",
              "Trainable params: 79,510\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 2.54\n",
              "==========================================================================================\n",
              "Input size (MB): 0.10\n",
              "Forward/backward pass size (MB): 0.03\n",
              "Params size (MB): 0.32\n",
              "Estimated Total Size (MB): 0.45\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F09Cqw6RVfi",
        "outputId": "bcfbab32-37ba-44eb-fd44-59ae8bb3df36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "ZqiGSML9-p9q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for params in model.parameters():\n",
        "    print(params.shape)"
      ],
      "metadata": {
        "id": "e9ufaSwS--Zw",
        "outputId": "8bdb0eba-8dd8-4a8e-aec5-aa98fed78abc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 784])\n",
            "torch.Size([100])\n",
            "torch.Size([10, 100])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batches = int(len(train_scaled)/32)\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for i in range(batches):\n",
        "        inputs = train_scaled[i*32:(i+1)*32].to(device)\n",
        "        targets = train_target[i*32:(i+1)*32].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(f\"에포크:{epoch + 1}, 손실:{train_loss/batches:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y_lnuYWFFp6",
        "outputId": "2ffe3f19-ee0d-4853-c9af-b51885768a87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크:1, 손실:0.5428\n",
            "에포크:2, 손실:0.4004\n",
            "에포크:3, 손실:0.3594\n",
            "에포크:4, 손실:0.3320\n",
            "에포크:5, 손실:0.3119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_scaled = val_scaled.to(device)\n",
        "    val_target = val_target.to(device)\n",
        "    outputs = model(val_scaled)\n",
        "    predicts = torch.argmax(outputs, 1)\n",
        "    corrects = (predicts == val_target).sum().item()\n",
        "\n",
        "accuracy = corrects / len(val_target)\n",
        "print(f\"검증 정확도: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUEWtfLa6pKu",
        "outputId": "463aa73d-e3ea-4ea0-ced9-7ead142d540c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 정확도: 0.8719\n"
          ]
        }
      ]
    }
  ]
}